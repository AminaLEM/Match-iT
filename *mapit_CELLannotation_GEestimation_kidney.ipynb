{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca37e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 23:51:53.193815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-09 23:51:53.386435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-01-09 23:51:53.386470: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-01-09 23:51:54.730694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-09 23:51:54.730881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-09 23:51:54.730888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/lemsaraa/miniconda3/envs/env1/lib/python3.10/site-packages/stlearn/tools/microenv/cci/het.py:192: NumbaDeprecationWarning: \u001b[1mThe keyword argument 'nopython=False' was supplied. From Numba 0.59.0 the default is being changed to True and use of 'nopython=False' will raise a warning as the argument will have no effect. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(parallel=True, nopython=False)\n"
     ]
    }
   ],
   "source": [
    "from src.ot_annotator2 import OTAnnotator\n",
    "import time\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hyperopt import hp\n",
    "import stlearn as st\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ba01bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: tab_out3\n"
     ]
    }
   ],
   "source": [
    "# output folder\n",
    "out_folder = \"tab_out3\"\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "else:\n",
    "    print(f\"Folder already exists: {out_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ec2fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "dataset_paths = {\n",
    "  '0027291__Region_1__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027291__Region_2__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027291__Region_3__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027291__Region_4__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",    \n",
    "  '0027292__Region_1__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027292__Region_2__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027292__Region_3__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027292__Region_4__20240530__125814' : \"/data/lemsaraa/amina/ST/ourData/20240530__124752__A4413_ST014_X0069_X0070/output-XETG00046__\",\n",
    "  '0027119__Region_1__20240621__120943': \"/data/lemsaraa/amina/ST/ourData/20240621__120000__ST014_X0071_X0072_A4413/output-XETG00046__\",\n",
    "  '0027119__Region_2__20240621__120943': \"/data/lemsaraa/amina/ST/ourData/20240621__120000__ST014_X0071_X0072_A4413/output-XETG00046__\",\n",
    "  '0027120__Region_1__20240621__120943':\"/data/lemsaraa/amina/ST/ourData/20240621__120000__ST014_X0071_X0072_A4413/output-XETG00046__\",\n",
    "  '0027120__Region_2__20240621__120943': \"/data/lemsaraa/amina/ST/ourData/20240621__120000__ST014_X0071_X0072_A4413/output-XETG00046__\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb76b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperopt parameter space\n",
    "# param_space = {\n",
    "#             \"reg\": hp.loguniform(\"reg\", np.log(0.0001), np.log(1)),\n",
    "#             \"reg_m_kl_1\": hp.loguniform(\"reg_m_kl_1\", np.log(0.0001), np.log(10)), #hp.uniform(\"reg_m_kl_1\", 0, 500),\n",
    "#             \"reg_m_kl_2\":hp.loguniform(\"reg_m_kl_2\", np.log(0.0001), np.log(10)),# hp.uniform(\"reg_m_kl_2\", 0, 500),\n",
    "#             \"method\": hp.choice(\"method\", ['sinkhorn']),\n",
    "#             \"reg_type\": hp.choice(\"reg_type\", ['entropy'])\n",
    "#         }\n",
    "param_space = {\n",
    "            \"reg\": hp.loguniform(\"reg\", np.log(0.0001), np.log(1)),\n",
    "            \"reg_m_kl_1\": hp.choice(\"reg_m_kl_1\",[float('inf'),hp.loguniform(\"reg_m_kl_1_\", np.log(0.0001), np.log(10))]), #hp.uniform(\"reg_m_kl_1\", 0, 500),\n",
    "            \"reg_m_kl_2\": hp.choice(\"reg_m_kl_2\",[float('inf'),hp.loguniform(\"reg_m_kl_2_\", np.log(0.0001), np.log(10))]),# hp.uniform(\"reg_m_kl_2\", 0, 500),\n",
    "            \"method\": hp.choice(\"method\", ['sinkhorn']),\n",
    "            \"reg_type\": hp.choice(\"reg_type\", ['kl'])\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89652c98",
   "metadata": {},
   "source": [
    "# Load scRNAseq reference data with cell annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55aaba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DCT', 'DCT_CNT', 'DTL-ATL', 'EC1', 'EC1_EC2', 'EC2', 'Fib',\n",
       "       'Fib_Mo', 'Fib_PTS', 'Fib_TAL', 'ICA', 'ICB', 'MC', 'Mo', 'PC',\n",
       "       'PEC', 'PTS1', 'PTS2', 'PTS3', 'PTS_Injured', 'Pod', 'Pod_Injured',\n",
       "       'Pod_Mixed', 'Pod_mut4', 'Prol', 'SMC', 'TAL', 'Tcell',\n",
       "       'Tcell_mixed', 'Uro'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=pd.read_csv('/data/lemsaraa/amina/ST/Xenium_analysis/tab/sc_metadata2.csv',index_col=0)\n",
    "metadata.head()\n",
    "\n",
    "samples = {\n",
    "    \"BDP1083\": \"/data/lemsaraa/amina/ST/ourData/sc/06092024/cellranger/BDP1083_filtered_seurat_comp.h5\",\n",
    "    \"BDP1105\": \"/data/lemsaraa/amina/ST/ourData/sc/06092024/cellranger/BDP1105_filtered_seurat_comp.h5\",\n",
    "    \"BDP1130\": \"/data/lemsaraa/amina/ST/ourData/sc/06092024/cellranger/BDP1130_filtered_seurat_comp.h5\",\n",
    "    \"BDP1131\": \"/data/lemsaraa/amina/ST/ourData/sc/06092024/cellranger/BDP1131_filtered_seurat_comp.h5\",\n",
    "}\n",
    "adatas = {}\n",
    "for sample_id, path in samples.items():\n",
    "    sample_adata = sc.read_10x_h5(path)\n",
    "    sample_adata.obs_names= sample_id+'_'+sample_adata.obs_names\n",
    "    sample_adata.var_names_make_unique()\n",
    "    adatas[sample_id] = sample_adata\n",
    "\n",
    "adata_ref = ad.concat(adatas, label=\"sample\")\n",
    "adata_ref=adata_ref[metadata.index,:]\n",
    "adata_ref.obs=metadata\n",
    "adata_ref=adata_ref[adata_ref.obs['celltype_l2']!='Unknown',:]\n",
    "np.unique(adata_ref.obs['celltype_l2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092c07c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute pearson correlation and cosine similarity for reconstructed genes\n",
    "def calculate_similarity(annotator, gene_interest, leftout, output_file):\n",
    "    from numpy.linalg import norm\n",
    "    if way=='all':\n",
    "        obs_names = annotator.adata.obs_names\n",
    "        X_org = pd.DataFrame(\n",
    "            annotator.adata[:, gene_interest].X.toarray(), columns=gene_interest)\n",
    "        X_org.index = obs_names\n",
    "    else:\n",
    "        annotator.adata=annotator._compute_celltype_means(annotator.adata, key='membership', gene_interest=annotator.gene_interest)        \n",
    "        obs_names = annotator.adata.obs_names\n",
    "        X_org = pd.DataFrame(\n",
    "            annotator.adata[:, gene_interest].X.toarray(), columns=gene_interest)\n",
    "        X_org.index = obs_names\n",
    "        \n",
    "        \n",
    "    annotator.X_reconstructed.index = obs_names\n",
    "    X_pred = annotator.X_reconstructed.loc[:, gene_interest]\n",
    "\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    for gene in leftout:\n",
    "        # Calculate correlation\n",
    "        correlation = np.corrcoef(X_pred[gene].values, X_org[gene].values)[0, 1]\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        vec1 = X_pred[gene].values\n",
    "        vec2 = X_org[gene].values\n",
    "        cosine_similarity = np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))\n",
    "\n",
    "        # Append results as a dictionary\n",
    "        results.append({\n",
    "            'gene': gene,\n",
    "            'correlation': correlation,\n",
    "            'cosine': cosine_similarity\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc119760",
   "metadata": {},
   "source": [
    "# Cell Annotation (per cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='CellAnnotation'\n",
    "way = 'all'\n",
    "verbose = True\n",
    "nb_cluster = 10\n",
    "metric = 'cosine'\n",
    "op_iter = 100\n",
    "key_ref = 'celltype_l2'\n",
    "key_tar = 'leiden'\n",
    "\n",
    "# Iterate through datasets and their paths\n",
    "for DATASET, DATA_DIR in dataset_paths.items():\n",
    "    if verbose:\n",
    "        # Open a log file for verbose output\n",
    "        log_file = open(f\"{out_folder}/{task}_{DATASET}_verbose_mapit_{way}_{key_ref}.log\", \"w\")\n",
    "        sys.stdout = log_file  # Redirect print to the log file\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        ##Configuration:\n",
    "        Task = {task}\n",
    "        DATASET = {DATA_DIR + '/' + DATASET}\n",
    "        mapping_strategy = {way}\n",
    "        distance_metric = {metric}\n",
    "        reference_annotation = {key_ref}\n",
    "        target_clustering = {key_tar}\n",
    "        nb_clusters = {nb_cluster}        \n",
    "        HyperOPT_iterations = {op_iter}\n",
    "        \"\"\")\n",
    "\n",
    "    # Path for the current dataset\n",
    "    path = DATA_DIR + DATASET + \"/\"\n",
    "    start_time = time.time() \n",
    "    print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")    \n",
    "    # Read Xenium dataset\n",
    "    adata = st.ReadXenium(\n",
    "        feature_cell_matrix_file=path + \"cell_feature_matrix.h5\",\n",
    "        cell_summary_file=path + \"cells.csv.gz\"\n",
    "    )\n",
    "    \n",
    "    # Identify genes of interest\n",
    "    gene_interest = adata_ref.var_names.intersection(adata.var_names)\n",
    "    # Initialize OTAnnotator\n",
    "    \n",
    "    annotator = OTAnnotator(\n",
    "        adata, \n",
    "        adata_ref, \n",
    "        gene_interest, \n",
    "        param_space=param_space,\n",
    "        key_ref=key_ref, \n",
    "        key_tar=key_tar, \n",
    "        way=way, \n",
    "        verbose=verbose\n",
    "    )\n",
    "    print('***Step1: Subcluster reference and target***') \n",
    "    annotator.subcluster(nb_cluster=nb_cluster)\n",
    "    print('***Step2: Mapping***')\n",
    "    annotator.annotate(op_iter=op_iter, metric=metric)\n",
    "    annotator.adata.obs[['predicted_annotation']].to_csv(f\"{out_folder}/{task}_{DATASET}_mapit_{way}_{key_ref}.csv\")        \n",
    "    end_time = time.time()\n",
    "    print(f\"End time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Restore standard output and close the log file\n",
    "    if verbose:\n",
    "        print(\"\\nEnded successfully.\") \n",
    "        sys.stdout = sys.__stdout__  # Reset to normal console output\n",
    "        log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffc1a5",
   "metadata": {},
   "source": [
    "# Cell Annotation (per subcluster of cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='CellAnnotation'\n",
    "way = 'mean'\n",
    "verbose = True\n",
    "nb_cluster = 10\n",
    "metric = 'cosine'\n",
    "op_iter = 100\n",
    "key_ref = 'celltype_l2'\n",
    "key_tar = 'leiden'\n",
    "\n",
    "# Iterate through datasets and their paths\n",
    "for DATASET, DATA_DIR in dataset_paths.items():\n",
    "    if verbose:\n",
    "        # Open a log file for verbose output\n",
    "        log_file = open(f\"{out_folder}/{task}_{DATASET}_verbose_mapit_{way}_{key_ref}.log\", \"w\")\n",
    "        sys.stdout = log_file  # Redirect print to the log file\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        ##Configuration:\n",
    "        Task = {task}\n",
    "        DATASET = {DATA_DIR + '/' + DATASET}\n",
    "        mapping_strategy = {way}\n",
    "        distance_metric = {metric}\n",
    "        reference_annotation = {key_ref}\n",
    "        target_clustering = {key_tar}\n",
    "        nb_clusters = {nb_cluster}        \n",
    "        HyperOPT_iterations = {op_iter}\n",
    "        \"\"\")\n",
    "\n",
    "    # Path for the current dataset\n",
    "    path = DATA_DIR + DATASET + \"/\"\n",
    "    start_time = time.time() \n",
    "    print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")    \n",
    "    # Read Xenium dataset\n",
    "    adata = st.ReadXenium(\n",
    "        feature_cell_matrix_file=path + \"cell_feature_matrix.h5\",\n",
    "        cell_summary_file=path + \"cells.csv.gz\"\n",
    "    )\n",
    "    \n",
    "    # Identify genes of interest\n",
    "    gene_interest = adata_ref.var_names.intersection(adata.var_names)\n",
    "    # Initialize OTAnnotator\n",
    "    \n",
    "    annotator = OTAnnotator(\n",
    "        adata, \n",
    "        adata_ref, \n",
    "        gene_interest, \n",
    "        param_space=param_space,\n",
    "        key_ref=key_ref, \n",
    "        key_tar=key_tar, \n",
    "        way=way, \n",
    "        verbose=verbose\n",
    "    )\n",
    "    print('***Step1: Subcluster reference and target***') \n",
    "    annotator.subcluster(nb_cluster=nb_cluster)\n",
    "    print('***Step2: Mapping***')\n",
    "    annotator.annotate(op_iter=op_iter, metric=metric)\n",
    "    annotator.adata.obs[['predicted_annotation']].to_csv(f\"{out_folder}/{task}_{DATASET}_mapit_{way}_{key_ref}.csv\")        \n",
    "    end_time = time.time()\n",
    "    print(f\"End time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Restore standard output and close the log file\n",
    "    if verbose:\n",
    "        print(\"\\nEnded successfully.\") \n",
    "        sys.stdout = sys.__stdout__  # Reset to normal console output\n",
    "        log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683e0e9",
   "metadata": {},
   "source": [
    "# LeftOut Genes Estimation (per cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a61a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='GEestimation'\n",
    "way = 'all'\n",
    "verbose = True\n",
    "nb_cluster = 10\n",
    "metric = 'cosine'\n",
    "op_iter = 100\n",
    "key_ref = 'celltype_l2'\n",
    "key_tar = 'leiden'\n",
    "leftout = ['Wt1', 'Nphs2', 'Podxl', 'Cldn2', 'Igfbp5', 'Vim', 'Plvap', 'Cp', 'Ctss', 'Pck1']\n",
    "\n",
    "# Iterate through datasets and their paths\n",
    "for DATASET, DATA_DIR in dataset_paths.items():\n",
    "    if verbose:\n",
    "        # Open a log file for verbose output\n",
    "        log_file = open(f\"{out_folder}/{task}_{DATASET}_verbose_mapit_{way}_{key_ref}.log\", \"w\")\n",
    "        sys.stdout = log_file  # Redirect print to the log file\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        ##Configuration:\n",
    "        Task = {task}\n",
    "        DATASET = {DATA_DIR + '/' + DATASET}\n",
    "        mapping_strategy = {way}\n",
    "        distance_metric = {metric}\n",
    "        reference_annotation = {key_ref}\n",
    "        target_clustering = {key_tar}\n",
    "        leftout_genes = {leftout}\n",
    "        nb_clusters = {nb_cluster}        \n",
    "        HyperOPT_iterations = {op_iter}\n",
    "        \"\"\")\n",
    "\n",
    "    # Path for the current dataset\n",
    "    path = DATA_DIR + DATASET + \"/\"\n",
    "    start_time = time.time() \n",
    "    print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")    \n",
    "    # Read Xenium dataset\n",
    "    adata = st.ReadXenium(\n",
    "        feature_cell_matrix_file=path + \"cell_feature_matrix.h5\",\n",
    "        cell_summary_file=path + \"cells.csv.gz\"\n",
    "    )\n",
    "    \n",
    "    # Identify genes of interest\n",
    "    gene_interest_ = adata_ref.var_names.intersection(adata.var_names)\n",
    "    gene_interest = [gene for gene in gene_interest_ if gene not in leftout]\n",
    "    # Initialize OTAnnotator\n",
    "    \n",
    "    annotator = OTAnnotator(\n",
    "        adata, \n",
    "        adata_ref, \n",
    "        gene_interest, \n",
    "        param_space=param_space,\n",
    "        key_ref=key_ref, \n",
    "        key_tar=key_tar, \n",
    "        way=way, \n",
    "        verbose=verbose\n",
    "    )\n",
    "    print('***Step1: Subcluster reference and target***') \n",
    "    annotator.subcluster(nb_cluster=nb_cluster)\n",
    "    print('***Step2: Mapping***')\n",
    "    annotator.annotate(op_iter=op_iter, metric=metric)\n",
    "    print('***Step3: Evaluate Reconstruction***')\n",
    "    # Calculate similarity and save to file\n",
    "    calculate_similarity(\n",
    "        annotator, \n",
    "        gene_interest_, \n",
    "        leftout, \n",
    "        f\"{out_folder}/{task}_{DATASET}_mapit_{way}_{key_ref}.csv\"\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"End time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "    print(annotator.best_params)\n",
    "    # Restore standard output and close the log file\n",
    "    if verbose:\n",
    "        print(\"\\nEnded successfully.\") \n",
    "        sys.stdout = sys.__stdout__  # Reset to normal console output\n",
    "        log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe2f95",
   "metadata": {},
   "source": [
    "# LeftOut Genes Estimation (per subcluster of cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='GEestimation'\n",
    "way = 'mean'\n",
    "verbose = True\n",
    "nb_cluster = 10\n",
    "metric = 'cosine'\n",
    "op_iter = 100\n",
    "key_ref = 'celltype_l2'\n",
    "key_tar = 'leiden'\n",
    "leftout = ['Wt1', 'Nphs2', 'Podxl', 'Cldn2', 'Igfbp5', 'Vim', 'Plvap', 'Cp', 'Ctss', 'Pck1']\n",
    "\n",
    "# Iterate through datasets and their paths\n",
    "for DATASET, DATA_DIR in dataset_paths.items():\n",
    "    if verbose:\n",
    "        # Open a log file for verbose output\n",
    "        log_file = open(f\"{out_folder}/{task}_{DATASET}_verbose_mapit_{way}_{key_ref}.log\", \"w\")\n",
    "        sys.stdout = log_file  # Redirect print to the log file\n",
    "        \n",
    "        print(f\"\"\"\n",
    "        ##Configuration:\n",
    "        Task = {task}\n",
    "        DATASET = {DATA_DIR + '/' + DATASET}\n",
    "        mapping_strategy = {way}\n",
    "        distance_metric = {metric}\n",
    "        reference_annotation = {key_ref}\n",
    "        target_clustering = {key_tar}\n",
    "        leftout_genes = {leftout}\n",
    "        nb_clusters = {nb_cluster}        \n",
    "        HyperOPT_iterations = {op_iter}\n",
    "        \"\"\")\n",
    "\n",
    "    # Path for the current dataset\n",
    "    path = DATA_DIR + DATASET + \"/\"\n",
    "    start_time = time.time() \n",
    "    print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")    \n",
    "    # Read Xenium dataset\n",
    "    adata = st.ReadXenium(\n",
    "        feature_cell_matrix_file=path + \"cell_feature_matrix.h5\",\n",
    "        cell_summary_file=path + \"cells.csv.gz\"\n",
    "    )\n",
    "    \n",
    "    # Identify genes of interest\n",
    "    gene_interest_ = adata_ref.var_names.intersection(adata.var_names)\n",
    "    gene_interest = [gene for gene in gene_interest_ if gene not in leftout]\n",
    "    # Initialize OTAnnotator\n",
    "    \n",
    "    annotator = OTAnnotator(\n",
    "        adata, \n",
    "        adata_ref, \n",
    "        gene_interest, \n",
    "        param_space=param_space,\n",
    "        key_ref=key_ref, \n",
    "        key_tar=key_tar, \n",
    "        way=way, \n",
    "        verbose=verbose\n",
    "    )\n",
    "    print('***Step1: Subcluster reference and target***') \n",
    "    annotator.subcluster(nb_cluster=nb_cluster)\n",
    "    print('***Step2: Mapping***')\n",
    "    annotator.annotate(op_iter=op_iter, metric=metric)\n",
    "    print('***Step3: Evaluate Reconstruction***')\n",
    "    # Calculate similarity and save to file\n",
    "    calculate_similarity(\n",
    "        annotator, \n",
    "        gene_interest_, \n",
    "        leftout, \n",
    "        f\"{out_folder}/{task}_{DATASET}_mapit_{way}_{key_ref}.csv\"\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"End time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "    print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Restore standard output and close the log file\n",
    "    if verbose:\n",
    "        print(\"\\nEnded successfully.\") \n",
    "        sys.stdout = sys.__stdout__  # Reset to normal console output\n",
    "        log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f94e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# comp_viz=compare_viz(annotator.adata[:,gene_interest],annotator.adata_ref[:,gene_interest],'cell_type_lvl4')\n",
    "\n",
    "# markers=['Rac2','Slc5a1','Kng2','Clcnkb','Kcnj1','Nox4','Gatm','Thsd7a','Smarca2','Mmp9','Anxa2','Kdr','Rgcc','Tie1','Bst1','Itga8','Myl9','Fbln5','Bgn','Cfh','Plat']\n",
    "# comp_viz.dotplot('predicted_annotation','Tcell',['dot'],markers)\n",
    "# comp_viz.dotplot('dot','Tcell',['predicted_annotation'],markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotT=plot_hp(annotator.trials,list(param_space.keys()))\n",
    "# plotT.plot_trials()\n",
    "# plotT.trials_loss_history('tt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e8b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task='CellAnnotation_SRcosine'\n",
    "# way = 'all'\n",
    "# verbose = True\n",
    "# nb_cluster = 10\n",
    "# metric = 'cosine'\n",
    "# op_iter = 100\n",
    "# key_ref = 'celltype_l2'\n",
    "# key_tar = 'leiden'\n",
    "\n",
    "# # Iterate through datasets and their paths\n",
    "# for DATASET, DATA_DIR in dataset_paths.items():\n",
    "#     if verbose:\n",
    "#         # Open a log file for verbose output\n",
    "#         log_file = open(f\"{out_folder}/{task}_{DATASET}_verbose_mapit_{way}_{key_ref}.log\", \"w\")\n",
    "#         sys.stdout = log_file  # Redirect print to the log file\n",
    "        \n",
    "#         print(f\"\"\"\n",
    "#         ##Configuration:\n",
    "#         Task = {task}\n",
    "#         DATASET = {DATA_DIR + '/' + DATASET}\n",
    "#         mapping_strategy = {way}\n",
    "#         distance_metric = {metric}\n",
    "#         reference_annotation = {key_ref}\n",
    "#         target_clustering = {key_tar}\n",
    "#         nb_clusters = {nb_cluster}        \n",
    "#         HyperOPT_iterations = {op_iter}\n",
    "#         \"\"\")\n",
    "\n",
    "#     # Path for the current dataset\n",
    "#     path = DATA_DIR + DATASET + \"/\"\n",
    "#     start_time = time.time() \n",
    "#     print(f\"Start time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))}\")    \n",
    "#     # Read Xenium dataset\n",
    "#     adata = st.ReadXenium(\n",
    "#         feature_cell_matrix_file=path + \"cell_feature_matrix.h5\",\n",
    "#         cell_summary_file=path + \"cells.csv.gz\"\n",
    "#     )\n",
    "    \n",
    "#     # Identify genes of interest\n",
    "#     gene_interest = adata_ref.var_names.intersection(adata.var_names)\n",
    "#     # Initialize OTAnnotator\n",
    "    \n",
    "#     annotator = OTAnnotator(\n",
    "#         adata, \n",
    "#         adata_ref, \n",
    "#         gene_interest, \n",
    "#         param_space=param_space,\n",
    "#         key_ref=key_ref, \n",
    "#         key_tar=key_tar, \n",
    "#         way=way, \n",
    "#         verbose=verbose\n",
    "#     )\n",
    "#     print('***Step1: Subcluster reference and target***') \n",
    "#     annotator.subcluster(nb_cluster=nb_cluster)\n",
    "#     print('***Step2: Mapping***')\n",
    "#     annotator.annotate(op_iter=op_iter, metric=metric)\n",
    "#     annotator.adata.obs[['predicted_annotation']].to_csv(f\"{out_folder}/{task}_{DATASET}_mapit_{way}_{key_ref}.csv\")        \n",
    "#     end_time = time.time()\n",
    "#     print(f\"End time: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(end_time))}\")\n",
    "#     print(f\"Execution time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "#     # Restore standard output and close the log file\n",
    "#     if verbose:\n",
    "#         print(\"\\nEnded successfully.\") \n",
    "#         sys.stdout = sys.__stdout__  # Reset to normal console output\n",
    "#         log_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee600e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
